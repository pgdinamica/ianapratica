{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pgdinamica/ianapratica/blob/main/notebooks/transcricao_whisper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_E3N4C5sw4Dy"
      },
      "source": [
        "# Baixando o áudio de um vídeo do YouTube"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Links:\n",
        "\n",
        "https://openai.com/research/whisper\n",
        "\n",
        "https://pypi.org/project/openai-whisper/\n",
        "\n",
        "https://pypi.org/project/yt-dlp/\n"
      ],
      "metadata": {
        "id": "CgQ7E365-CHf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VY5YeUwv9_7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63d66163-55ab-48f5-9830-17a324faac59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-r3qeqyko\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-r3qeqyko\n",
            "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.2)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper==20231117)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.13.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch->openai-whisper==20231117)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch->openai-whisper==20231117)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch->openai-whisper==20231117)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch->openai-whisper==20231117)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch->openai-whisper==20231117)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch->openai-whisper==20231117)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch->openai-whisper==20231117)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper==20231117)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802826 sha256=b0c13f7bbf3a6402e14c3546c659de69e9cf484f90387c44c47b8a5a4d1a5c2f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bwm6ujpg/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 openai-whisper-20231117 tiktoken-0.6.0\n",
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2024.3.10-py3-none-any.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai\n",
            "  Downloading openai-1.14.0-py3-none-any.whl (257 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.5/257.5 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting brotli (from yt-dlp)\n",
            "  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2024.2.2)\n",
            "Collecting mutagen (from yt-dlp)\n",
            "  Downloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodomex (from yt-dlp)\n",
            "  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2.31.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.17 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2.0.7)\n",
            "Collecting websockets>=12.0 (from yt-dlp)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.31.0->yt-dlp) (3.3.2)\n",
            "Installing collected packages: brotli, websockets, pycryptodomex, mutagen, h11, yt-dlp, httpcore, httpx, openai\n",
            "Successfully installed brotli-1.1.0 h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 mutagen-1.47.0 openai-1.14.0 pycryptodomex-3.20.0 websockets-12.0 yt-dlp-2024.3.10\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install yt-dlp openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_url = 'https://www.youtube.com/watch?v=i6l3R7j95x8'"
      ],
      "metadata": {
        "id": "Gj2nGc9wJwvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!yt-dlp -x -f bestaudio --audio-format mp3 -o \"%(id)s.%(ext)s\" $video_url"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssRdVdSiK2_g",
        "outputId": "d4d54a8b-d12f-4838-ffde-bccd395ff923"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=i6l3R7j95x8\n",
            "[youtube] i6l3R7j95x8: Downloading webpage\n",
            "[youtube] i6l3R7j95x8: Downloading ios player API JSON\n",
            "[youtube] i6l3R7j95x8: Downloading android player API JSON\n",
            "[youtube] i6l3R7j95x8: Downloading m3u8 information\n",
            "[info] i6l3R7j95x8: Downloading 1 format(s): 251\n",
            "[download] Destination: i6l3R7j95x8.webm\n",
            "\u001b[K[download] 100% of   15.36MiB in \u001b[1;37m00:00:00\u001b[0m at \u001b[0;32m40.30MiB/s\u001b[0m\n",
            "[ExtractAudio] Destination: i6l3R7j95x8.mp3\n",
            "Deleting original file i6l3R7j95x8.webm (pass -k to keep)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transcrição de textos em Português com whisper (OpenAI)"
      ],
      "metadata": {
        "id": "55AXNHcqRl7C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelos disponíveis\n",
        "\n",
        "Você pode escolher qual o tamanho de modelo deseja usar. Os tamanhos impactam na qualidade do resultado e no tempo de processamento (quanto melhor a qualidade, mais tempo de processamento). A escolha entre eles também está à qualidade do áudio: se poluído com ruídos, provavelmente será necessário um modelo com maior qualidade para conseguir transcrever corretamente.\n",
        "\n",
        "A lista de possíveis modelos é, do mais rápido para o fim o maior qualidade:\n",
        "\n",
        "- tiny\n",
        "- base\n",
        "- small\n",
        "- medium\n",
        "- large"
      ],
      "metadata": {
        "id": "-r4JF8esMMyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper"
      ],
      "metadata": {
        "id": "hfROlh4mJwyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model('tiny')\n",
        "result = model.transcribe('i6l3R7j95x8.mp3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsJOBCrKMGNj",
        "outputId": "9049ccf9-23a9-42a9-a026-2cabacd03ef9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 72.1M/72.1M [00:01<00:00, 43.4MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Result ==> Video: i6l3R7j95x8  Model: Tiny <==')\n",
        "for sentence in result[\"text\"].split('.'):\n",
        "  print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "myGyes5FNolH",
        "outputId": "902b46a7-fd2e-42f7-a9d2-1c8ca06b8b87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' No IITAS Complicado de hoje, você vai aprender o que são reddeno-gares. Mas tem uma ideia de como as reddeno-gares funcionam e também de porque elas são tão poderosas. Porque que nós utilizamos reddeno-gares para fazer aplicações que vão desde e identificar pessoas e contar objetos até mesmo as gerarteis, imagens e vídeos de alta qualidade. Pá pessoal, sou o ALo e esse canal para uma sandinâmica. Se você caiu aqui de paiaquedas, seja bem-vindo. Aqui me espassem que eu e aqui, ensinamos discutimos sobre programação, ser cidados, intergência especial e também o impacto de novas tecnologias na sociedade. E hoje a gente vai falar sobre reddeno-gares artificiais. A ideia do IITAS Complicado é trazer uma explicação que seja acessível sobre intergência especial, mas que não seja superficial. De modo que você possa realmente aprender algo além do que você encontra em na mídia, e fazendo jornais do que as pessoas estão falando de uma nega geral. Eu imagine que quando você escuta reddeno-gao, você pensa em hiáginegativa, então é o que a gente é especial, temos que ter um ser bastante debatidos. Principalmente por conta de algumas aplicações como chat de PT, da LINE, a MiGernie e agora mais recentemente esse suger da OP&AI que é capaz de inclusive de jogar vídeos em alta resolução. Então essa aplicação é realmente bem impressionante, e até trazem um certo receio, um medo nas pessoas, enfim, de ser insumituitas, ou por consequências em aplicações do mal uso da intergência especial. Aliás, se você quiser saber o que é e o que possivelmente não é a intergência especial, você pode assistir ao primeiro vídeo da CIA e a descomplicada, em que a crise discute exatamente isso, e inclusive apresentar uma apementar muito interessante para você analisar situações diferentes. Mas antes de discutir essa ponta da IA, eu vou te trazer por outro extremo para a gente realmente entender o que é uma rede neural artificial. Então uma rede neural artificial é um modelo computacional. Para essa ter que eu estou complicando, trazer esse termo, essa expressão que você pode não ter fagunha a idade, mas é aí que entra, explicação acessível, mas não superficial. Então, eu não tentar entender o que é um modelo, o modelo é um tipo de representação, algo que a gente utiliza para poder compreender um fenômeno. Então, na escola, por exemplo, na química, você estudou sobre o modelo do átomo, de que as coisas no mundo são constituídas por pequenas partículas, por meio alguém pensou que existiria uma pequena partícula indivisível e aí chamou isso de átomo. Então, tudo se é constituído desses átomos que vão se juntando para compor outros elementos, outras coisas mais complexas. E aí, posteriormente as pessoas de escubeu que o átomo pode ser decidido, que o lado entro tem partículas como os elétrons e os prótons. Então, criou-se um novo modelo, uma outra forma de representar aquela realidade, de você abstrair de se pensar sobre a realidade e tentar compreender aquilo. Então, a rede neural é um modelo computacional, é uma forma da gente simplificar, representar alguma coisa, com a finalidade de fazer contas, de computar. Então, nem sempre eu vou portar aqui o nome rede neural artificial, às vezes eu vou falar a rede neural, você pode entender que é a rede neural artificial. E porque estou fazendo essa distinção? Porque, de fato, existe em rede neurales não artificiales, às vezes do nosso cérebro mesmo. Então, a rede neural artificial é um modelo computacional que foi inspegado, não quer dizer que ele funciona como o nosso cérebro como a rede neural, e que foi inspegado pela forma como o cérebro ou o que a gente sabia sobre o cérebro funciona. Então, a gente sabe que no cérebro existem neurônios, existem unidades menores que se conectam, inclusive. Né, neurônios que estão conectados entre si, que vão transmitir na informação. Não é muito importante, eu reivante para a gente entender como que de fato esse processo, que em microbiológica acontece, mas essa em explicação de ter unidades menores, que faz algum tipo de processamento, algum tipo de compreensão de sinais que eles são passados e repasam isso para outras unidades similares, outros neurônios, essa ideia serve de em explicação para as redes neurales artificiales. Então, me acompanha aqui no quadro. Isso aqui é uma representação esquemática do que seguindo neurônio artificial, que a gente chama de Perceptrum. E você está vendo que ele tem algumas conexões, algumas formas de receber informações, de receber sinais. E vai realizar alguma operação, algum tipo de coisa, e vai repasar um resultado que a gente está vendo aqui com esse ozinho, ou de alt pute de saída em inglês. O que ele é capaz de fazer? Receber em tradas e receber sinais, que estão sendo representados aqui por x0, x1, x2 até xn. Então, basta você pensar que existem ene sinais, uma certa quantidade de informação, ou de dados que chegam neste neurônio artificial. O que vai fazer com isso? Uma conta, algo que vai fazer uma conta. Você não precisa entender muitos detalhes dessa conta, mas eu vou adiantar para você que ela é uma conta bem simples. É uma conta assim de somar e multiplicar. Então, este neurônio aqui artificial, essa coisa em verde, ele basicamente vai utilizar alguns números que estão sendo representados aqui por esses daabilhos, está vendo? Então, daabilidade de 8 em inglês, peso, então a gente diz que o neurônio tem peso. Então, que vai utilizar esses pesos aqui para fazer opégações de soma e multiplicação com os valores que estão recebendo aqui de entrada. São opégações bem simples mesmo, beleza? Este tipo de apégação está representado neste esquema por esse símbolo aqui, que a solução está muita gente, se muda somatória, se siga, às vezes pessoas não comprenem, e se não precisa nem olhar para forma aqui. Está abaixo saber que ele está redisendo aqui, vai fazer essas opégações de soma, multiplicação aqui. E também tem um outro tipo de apégação que é bastante importante que o neurônio artificial sabe fazer, que é uma apégação de não linegaridade. Basicamente, passar uma função diferente de soma e multiplicação, algo que seja mais complicado, com um por exemplo, um seno, uma tan gente, uma coisa que tem, em certa oscillaçãozinho, um pouquinho mais complicado. Essa função aqui não linear, representa na letra fíj, a gente chama de função de ativação. E, é basicamente, vem da ideia também, inspirado da biologia, de que os precisadores perceberam que nem todos os estimos que o neurônio recebe, o ativom, né? Existem alguns estimos que vão chegar ali no neurônio, e aí pode não repassar, tá? Aqui eu para a frente, pode ir para a beleza. Isso aqui chegou e ficou por ali mesmo. Então, para simular o pouco desse comportamento, cria ou se essa função de ativação, que basicamente vai olhar por resultado da vida, aquela combinação de todos os sinais que chegaram, aquela ação é uma multiplicação, ou tal, é fazer um tipo de operação que pode ser galinhada como, olha, esse neurônio tá realmente bem ativado, isso aqui é uma informação muito importante para ele, ou não, tá? Basicamente isso. Então, a gente acabou de ver um modelo computacional, inspirado em neurônio, que é o perceptron, essa é a única unidade, tá? E o interessante é que eles podem se conectar tal como os neurônios, né? Se conectam no cérebro, e aí a gente com um põe, este modelo mais avançado, que é a rede neural artificial. Se você fizer uma busca de imagem sobre rede neural, isso vai encontrar algo, parecido com esse outro esquema aqui, tá? Pode ser quadradinhos, pode ser balinhas que nem a gente estava vendo aí, o ponto é que você vai ter várias unidades similares que estão se conectando, tá? Então, cada um de dar a diferença aqui, que a gente está vendo, tá? Cada quadradinho desse aqui é um neurônio artificial, é um perceptron, é algo que tem, aqui na característica que a gente viu, de receber sinais, receber valores, fazer uma operação, olha isso, uma multiplicação, tá? Passava a função para dizer que está ativado, não? Dá uma resposta. E aqui, o que a gente está vendo é que a resposta de um neurônio está sendo conectada a diversos outros neurônios que estão aqui organizados em camadas, tá? Então, a gente tem uma camada aqui, tá? Chamando de camada de entrada, uma outra camada aqui, outra camada aqui, outra aqui, e podemos ter, né? E, sem since aqui indica, que você poderia ter diversas outras camadas, tá? Até você ter, de fato, no final, a saída, a saída total. Então, cada neurônio produz uma saída, o produto no resultado. E você tem esse modelo mais complexo que está fazendo várias contas, cada neurônio faz a sua conta e repasse o seu resultado para neurônios organizados em camadas, que vão fazer contas, né? Então, esse b se resultado não tem que ir, como se os sinais, como suas entradas, vão fazer com, desrepassar para frente e assim vai até que a gente obtém o resultado no final. Beleza? Então, é só isso, né? Pode parecer um pouco abistrato como que isso aqui, como que essas contas, né? Se conectam com o ear, mas a gente já vai começar a distrinchar alguns termos para você começar a compreender, tá? O primeiro deles é a ideia de Deep Learning, ou aprendizado o profundo, que você já deve ter escutado, né? Nesse contexto é muito fácil, quando você faz o que a pesquisa ou vi sobre Deep Learning, as pessoas falam de Pilar, a minha machine learning, que é isso, né? Então, o que a gente está falando de Deep Learning? A medida que essa escamada, os aumentam, tá? A medida que a gente vai botando mais camadas, aqui a gente diz que a rede está ficando mais profunda, tá? Bem aí do Deep de profundidade, né? Então, Deep Learning é essa aia, né? De aprendizado de máquina, de você ter modelos computacionais que vão aprender com dados, que utiliza redes neugais profundos, redes nagais com várias camadas, como essa, tá? Com as camadas que vão se organizando. Outra coisa que é interessante, cada perceptron tem aquele espécie para fazer conta, né? A gente chama aquele espécie usar de paiando metros, os valores que a gente vai utilizar para fazer multiplicação ou em soma, a gente chama de paiando metros, né? No modelo, paiando metros do perceptron e, no caso de uma rede general, quando você olha para todos os paiando metros de todos os neurônios artificiales, envolvidos os setemos paiando metros da rede. Então, quando você vê uma notícia do tipo assim, o chat de PT ou o Lama, o modelo de linguagem grande, né? Um grande modelo de linguagem, né? Ele é a LEM, como a gente me chamando. Tem cinco bilhões de paiando metros, o que as pessoas estão falando é que existem cinco bilhões de números como esse, tá? Como eles estão representados em cada, né? Um deus índice aqui. Beleza? E é muito fácil ver que esses números podem crescer de uma forma muito rápida, tá? Porque matematicamente essas contas aqui vão ser representadas por matrisis, tá bom? Então, não vou entrar no detalhe de como que a gente chega na matrisis, mas vou te dizer aqui que, por exemplo, neste primeiro caso, olhando para isso aqui, a gente tem quatro elementos aqui na entrada, e um, dois, três, quatro, cinco, seis, set, oito, nove, dez aqui nessa primeira camada escondida, né? Como a gente chama? Então, só isso aqui dá o pra gente uma matriz, que é quatro, por dez, tá bom? E cidadés, por quatro, enfim? Vai ter quarenta, quarenta, um, vejo aqui nessa matriz. E aí você vai fazer uma conta parecida para isso aqui, uma outra coisa aqui, então você vê assim, se você aumentar muito esse número de neurônios em cada camada, e esse em alguns modelos vai ter muito menos, você pode ter X-L-A, mil e tanto de neurônios em uma camada, mil e tanto na outra, mil vezes mil, já dá, um milhão, tá? Então, só pensando assim, se já consegue perceber que a quantidade de párram, no mesmo troço pode crescer bastante, e não modei o grande desse, como chatGPT, é o que está na ordem de bidões. Sim, esse tempo todo você teve medo de ser substituído por multiplicação de matrises. Agora, o fato que torna uma rede integral tão poderosa é que ela é um modelo computacional capaz de aproximar qualquer função. Então, não é mágica, gente? É mátima, digo, mátima, átima. Eu já expliquei algumas vezes aqui no canal, que é uma função. Vai vou morrar de maneira resumida, ela seria uma entidade, um objeto que transforma uma coisa, outra coisa, sem deixar dúvidas. Então, por exemplo, a função sulco poderia transformar uma fruta, um sulco da queda fruta, né? Lá ganja, em sulco de larganja, melancia, em sulco de melancia, olhando, em sulco de morango, sem deixar dúvidas, se olha ela transforma, não laranja em sulco de morango ou laranja em sulco de maçã, certo? Então, isso é uma função, uma forma de transformar o dia associar o elemento de conjunto, a elemento de outro conjunto, tá? Então, poder das redes no hagás está intimamente relacionado a nossa capacidade, né, a capacidade humana, de representar as coisas a nossa redor como funções, né? Você pode pensar, por exemplo, que existe uma função em que você dá uma imagem, e ela te diz se tem um gato ou não, certo? Ela transforma o que ela recebeu, imagem em uma resposta, sim, ou não, para a pergunta tem gato, certo? Então, você pode imaginar que existe uma função como essa, se pode imaginar que tem uma função que recebe também uma imagem e conta quanto esse lags existe naquele imagem, certo? Recebe uma imagem, um elemento de um conjunto, a função faz o que ela tem que fazer isso, não precisa saber exatamente como é que ela, o processo dela funciona, mas o ponto é que ela vai associar, para que ela imagem vai te dizer quanto os celulares existem. Se você vê a imagem de novo, quantas vezes foi a innecessária, certo? Você vai te dizer, olha, existem aqui, dizer, sei o lag, certo? Ela transforma isso naquilo sem deixar dúvida. No primeiro momento, isso pode parecer muito louco, né? Mas se você pega a papinça, tudo que está no computador tem que ser representado de uma maneira matemática, né? Na forma de números, aqui. Porque são coisas digitais, o computador e é uma máquina de computação. Então, ele faz operações muito simples, apesar de ser muito poderosas, de possibilitar por exemplo, que a gente esteja aqui, conversando nesse momento, que o possa passar a mensagem para vocês, você possa aprender você, você possa comentar aí, a gente possa continuar essa discussão aqui embaixo. Então, apesar da atividade, a gente possa fazer computador. Então, essas atividades você vê, seguem bem complexas, o tipo de operação de computadores, fazem essas operações, são muito simples. Então, se pode pensar aqui, é assim, tudo que você consegue ver no computador seja texto, imagem, vídeo ou qualquer outra coisa, já tem uma representação matemática, né? Uma remensação do Meika. Então, com esse contexto, dá para imaginar que existe uma longa literatura, né? Uma longa caminhada de estudos das pessoas pensando com a seguir a melhor maneira, né? E, né, de fazer esse tipo de representação, né, de objetos da realidade, num computador, com a seguir a melhor maneira de fazer operações com eles, né? Então, mesmo antes de você olhar para essa parte de ir à etal, seja podia fazer diversos operações com imagens, ali usando Photoshop, né? Para tomar uma coisa impertibiana, que o fazer composições, montagens e outras coisas, todas essas operações já foram muito bem estudadas. E, o poder mesmo da rede, não é? Ou bem, dessa capacidade de receber essas coisas como dados, como sinais, ali para que o expresse é a prum, fazer operações em cima daquilo, e ajustar esses pagamentos, né? Ajustar um número de cada um daqueles neurônios, ali na rede, de modo a produzir um resultado que você deseja. Então, a gente ganhou um grande poder ao ter um modelo que é bastante flexível, que é capaz de aprender praticamente qualquer função. E da gente ter a capacidade de especificar para esse modelo. Dados, comentrada, como sinais, dados na forma de números, e também especificar para ir e sair das respostas espéramadas também na forma de números. Então, dando os dados, dando a saída, e tendo um processo de ajuste, né? Ou, aí, te uma ligue que vem dessas técnicas de aprendizado de máquina para ajustar os pesos da rede, tendo isso a gente consegue treinar. O treinamento de uma rede no ala esse processo de ajustar esses números das contas que acontecem no meio. Então, com isso, a gente consegue treinar a justa a rede de modo que ela aprenda a utilizar essas entradas o que quer que seja existado no branelo, e reproduzir respostas espéramadas. É claro que há muitos outros detalhes de aportrar isso, principalmente com esse dedo, dando a variedade de problemas em que a gente vem aplicando o rede no ala. Por exemplo, a forma de treinar uma rede no ala, para reconhecer gatos em uma imagem, é a gente da forma de treinar uma rede no ala, para ensinar um agente como um robô, a caminhada, e tudo de um ambiente. Mas, as ideias por trás, né, a ideia de modelar o seu problema na forma de funções, de entender que você vai ter que passar dados nas sinais, além entrada, de que você vai ter que especificar de alguma maneira, algo que permite permitir, o qual correto com bom, né, aqui em que o resultado está ficando ou não, para que você possa ajustar os pezos da rede, fazer esse treinamento, essa ideia é ela se repete em diversos tipos de problemas. Então, pode parecer muito simples nas é realmente essa estrutura, e apenas essas operações, eu ir de soma e multiplicação com uma função, que vão se conectando só isso realmente que a gente tem feito para construir todas essas aplicações fantásticas que têm deixadas pessoas visúbradas. Se você quiser entender esses detalhes, como uma rede no ala e treinada, de como que esses algoritmos funcionam na prática, eu sugiro que você assista um vídeo aqui no canal, em que eu ensinei sobre Pytorte e redes no gás do zero, né, ensinei realmente como que você monta toda a infraestrutura para fazer o treinamento de uma rede no ala, utilizando da biblioteca Pytorte, que é uma biblioteca muito utilizada, né, para resolver esse tipo de problema, e fui explicando como é que você moderra o problema, como é que você entende a rede no ala com uma função, como que você aproxima uma função com ela, e a gente vai evoluindo até trabalhar com imagens mesmo, e discutir essas representações digitais. Se você goste do vídeo, não esquece de deixar o seu like e não se inscreveu aqui no canal, para dar que apoio a nossa trabalho, muito obrigado e até a próxima.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = whisper.load_model('small')\n",
        "result2 = model2.transcribe('i6l3R7j95x8.mp3')"
      ],
      "metadata": {
        "id": "vTV4xIQDMGZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Result ==> Video: i6l3R7j95x8  Model: Small <==')\n",
        "for sentence in result2[\"text\"].split('.'):\n",
        "  print(sentence)"
      ],
      "metadata": {
        "id": "U17AN8b9RbNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = whisper.load_model('medium')\n",
        "result3 = model3.transcribe('i6l3R7j95x8.mp3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydbR99tCJw56",
        "outputId": "ac36857a-ab8e-4523-8dc5-3c018adfe113"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 1.42G/1.42G [00:15<00:00, 99.8MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Result ==> Video: i6l3R7j95x8  Model: Medium <==')\n",
        "for sentence in result3[\"text\"].split('.'):\n",
        "  print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1WbehPCRR1i",
        "outputId": "788e2c53-371b-4b55-d9c0-5d265a32cfc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result ==> Video: i6l3R7j95x8  Model: Medium <==\n",
            " No Yaris Complicada de hoje, você vai aprender o que são redes neurais, vai ter uma ideia de como as redes neurais funcionam e também de porque elas são tão poderosas\n",
            " Por que nós utilizamos redes neurais para fazer aplicações que vão desde identificar pessoas e contar objetos, até mesmo a gerar textos, imagens e vídeos de alta qualidade\n",
            " Fala pessoal, eu sou o Alisson e esse é o canal Programação Dinâmica\n",
            " Se você caiu aqui de paraquedas, seja bem-vindo\n",
            " Aqui é um espaço em que eu e a Kize ensinamos e discutimos sobre programação, ciência de dados, inteligência artificial e também o impacto de novas tecnologias na sociedade\n",
            " E hoje a gente vai falar sobre redes neurais artificiais\n",
            " A ideia do Yaris Complicada é trazer uma explicação que seja acessível sobre inteligência artificial, mas que não seja superficial, de modo que você possa realmente aprender algo além do que você encontra na mídia, nos jornais, do que as pessoas estão falando de maneira geral\n",
            " Eu imagino que quando você escuta rede neural, você pensa em IA, IA generativa, inteligência artificial, termos que estão sendo bastante debatidos, principalmente por conta de algumas aplicações como o ChatGPT, Dali, Me Journey e agora mais recentemente esse Sora da OpenAI que é capaz inclusive de gerar vídeos em alta resolução\n",
            " Então essas aplicações elas são realmente bem impressionantes e elas até trazem um certo receio, um medo das pessoas, enfim, de serem substituídas ou por consequências e implicações do mal uso da inteligência artificial, né? Aliás, se você quiser saber o que é e o que possivelmente não é inteligência artificial, você pode assistir ao primeiro vídeo da série Yaris Complicada, em que a Kize discute exatamente isso e inclusive apresenta lá um mapa mental muito interessante para você analisar situações diferentes\n",
            " Mas antes da gente discutir essa ponta da IA, eu vou te trazer para um outro extremo para a gente realmente entender o que é uma rede neural artificial\n",
            " Então, uma rede neural artificial é um modelo computacional\n",
            " Parece até que eu estou complicando, né? Trazendo esse termo, essa expressão que você pode não ter familiaridade, mas é aí que entra explicação acessível, mas não superficial\n",
            " Então vamos tentar entender o que é um modelo\n",
            " Um modelo é um tipo de representação, né? Algo que a gente utiliza para poder compreender um fenômeno\n",
            " Então lá na escola, por exemplo, na química, você estudou sobre o modelo do átomo, né? De que as coisas no mundo são constituídas por pequenas partículas\n",
            " Primeiro alguém pensou que existiria uma pequena partícula indivisível e aí chamou isso de átomo\n",
            " Então tudo seria constituído desses átomos que vão se juntando para compor outros elementos, outras coisas mais complexas\n",
            " E aí posteriormente as pessoas descobriram que o átomo pode sim ser dividido\n",
            " Que lá dentro tem partículas como os elétrons e os prótons\n",
            " Então criou-se um novo modelo, uma outra forma de representar aquela realidade\n",
            " De você abstrair, de você pensar sobre a realidade e tentar compreender aquilo\n",
            " Então a rede neural é um modelo computacional\n",
            " Ela é uma forma de a gente simplificar, representar alguma coisa com a finalidade de fazer contas, de computar\n",
            " Beleza? Então nem sempre eu vou portar aqui o nome rede neural artificial\n",
            " Às vezes eu vou falar só rede neural, você pode entender que é rede neural artificial\n",
            " E por que eu estou fazendo essa distinção, né? Porque de fato existem redes neurais não artificiais, às vezes do nosso cérebro mesmo\n",
            " Então a rede neural artificial é um modelo computacional que foi inspirado\n",
            " Não quer dizer que ele funciona como nosso cérebro, como as redes neurais mesmo\n",
            " Ele foi inspirado pela forma como o cérebro, ou o que a gente sabia sobre o cérebro, funciona\n",
            " Então a gente sabe que no cérebro existem neurônios\n",
            " Existem unidades menores que se conectam, inclusive\n",
            " Neurônios que estão conectados entre si, que vão transmitir informação\n",
            " Não é muito importante, é relevante pra gente aqui entender como que de fato esse processo químico e biológico acontece, mas essa inspiração de ter unidades menores que fazem algum tipo de processamento, algum tipo de compreensão de sinais que lhes são passados e repassam isso pra outras unidades similares, outros neurônios\n",
            " Essa ideia serve de inspiração para as redes neurais artificiais\n",
            " Então me acompanhe aqui no quadro\n",
            " Isso aqui é uma representação esquemática do que seria um neurônio artificial, que a gente chama de perceptron\n",
            " E você está vendo que ele tem algumas conexões, algumas formas de receber informações, de receber sinais\n",
            " Ele vai realizar alguma operação, algum tipo de coisa aqui, e vai repassar um resultado que a gente está vendo aqui com esse O, de output, de saída em inglês\n",
            " O que ele é capaz de fazer? Receber entradas, receber sinais que estão sendo representados aqui por X0, X1, X2, até Xn\n",
            " Então basta você pensar que existem N sinais, uma certa quantidade de informação, de dados que chegam nesse neurônio artificial\n",
            " E o que ele vai fazer com isso? Uma conta\n",
            " Ele vai fazer uma conta\n",
            " Você não precisa entender muito dos detalhes dessa conta, mas eu vou adiantar pra você que ela é uma conta bem simples\n",
            " É uma conta assim de somar e multiplicar\n",
            " Então, esse neurônio aqui, artificial, essa coisinha em verde, ele basicamente vai utilizar alguns números que estão sendo representados aqui por esses W, está vendo? Então W vem de weight, em inglês, peso\n",
            " Então a gente diz que o neurônio tem peso\n",
            " Então ele vai utilizar esses pesos aqui pra fazer operações de soma e multiplicação com os valores que ele está recebendo aqui de entrada\n",
            " Que são operações bem simples mesmo, beleza? Então esse tipo de operação está representado nesse esquema por esse símbolo aqui, que assusta muita gente, né? O símbolo de somatório, esse sigma\n",
            " Às vezes as pessoas não compreendem, você não precisa nem olhar pra fórmula aqui, tá? Basta saber que ele está dizendo que vai fazer essas operações de soma e multiplicação aqui\n",
            " E também tem um outro tipo de operação que é bastante importante que o neurônio artificial sabe fazer, que é uma operação de não linearidade\n",
            " Basicamente, passar uma função diferente de soma e multiplicação, algo que seja mais complicado, tá? Como por exemplo um seno ou uma tangente, tá? Uma coisa que tem uma certa oscilaçãozinho um pouquinho mais complicada\n",
            " Essa função aqui, não linear, representada na letra phi, a gente chama de função de ativação\n",
            " Aí ela basicamente vem da ideia também inspirada da biologia, de que os pesquisadores perceberam que nem todos os estímulos que o neurônio recebe o ativam, né? Existem alguns estímulos que vão chegar ali no neurônio e ele pode não repassar, tá? Aqui ou pra frente, ele pode falar, beleza, isso aqui chegou e ficou por ali mesmo\n",
            " Então pra simular um pouco desse comportamento, criou-se essa função de ativação, que basicamente vai olhar pro resultado ali daquela combinação de todos os sinais que chegaram, tá? Aquela soma e multiplicação e tal, vai fazer um tipo de operação que pode ser avaliada como, olha, esse neurônio está realmente bem ativado, isso aqui é uma informação muito importante pra ele ou não, tá? Basicamente isso\n",
            " Então a gente acabou de ver um modelo computacional inspirado em um neurônio, que é o perceptron, essa única unidade, tá? E o interessante é que eles podem se conectar tal como os neurônios se conectam no cérebro, e aí a gente compõe este modelo mais avançado, que é a rede neural artificial\n",
            " Se você fizer uma busca de imagens sobre rede neural, aí você vai encontrar algo parecido com esse outro esquema aqui, tá? Pode ser quadradinhos, podem ser bolinhas, que nem a gente estava vendo ali, o ponto é que você vai ter várias unidades similares que estão se conectando, tá? Então cada unidade dessa aqui que a gente está vendo, tá? Cada quadradinho desse aqui, é um neurônio artificial, é um perceptron, é algo que tem aquela característica que a gente viu, de receber sinais, receber valores, fazer uma operação ali, soma, multiplicação, tá? Passar uma função para dizer se ele está ativado ou não, dar uma resposta\n",
            " E aqui, o que a gente está vendo é que a resposta de um neurônio está sendo conectada a diversos outros neurônios que estão aqui organizados em camadas, tá? Então a gente tem uma camada aqui, que está chamando de camada de entrada, uma outra camada aqui, outra camada aqui, outra aqui, E poderíamos ter, né? A reticência aqui indica que você poderia ter diversas outras camadas, tá? Até você ter, de fato, no final, a saída, a saída total\n",
            " Então cada neurônio produz uma saída, produz um resultado, e você tem esse modelo mais complexo que está fazendo várias contas, cada neurônio faz a sua conta e repassa o seu resultado para neurônios organizados em camadas, que vão fazer contas, vão receber esse resultado anterior como seus sinais, como suas entradas, vão fazer contas e repassar para frente, e assim vai, até que a gente obtenha o resultado no final\n",
            " Beleza? Então é só isso, né? Pode parecer um pouco abstrato como que isso aqui, como que essas contas se conectam com o IA, mas a gente já vai começar a destrinchar alguns termos para você começar a compreender, tá? O primeiro deles é a ideia de deep learning, ou aprendizado profundo, que você já deve ter escutado, né? Nesse contexto é muito fácil quando você faz qualquer pesquisa ouvir sobre deep learning, e as pessoas falam, deep learning, machine learning, o que que é isso, né? Então, o que que a gente está falando de deep learning? À medida que essas camadas aumentam, tá? À medida que a gente vai botando mais camadas aqui, a gente diz que a rede está ficando mais profunda, tá? Vem aí do deep de profundidade, né? Então, deep learning é essa área de aprendizado de máquina, de você ter modelos computacionais que vão aprender com dados, que utiliza redes neurais profundas, redes neurais com várias camadas como essa, tá? Várias camadas que vão se organizando\n",
            " Outra coisa que é interessante, cada perceptron tem aqueles pesos para fazer conta, né? A gente chama aqueles pesos lá de parâmetros, os valores que a gente vai utilizar para fazer as multiplicações e somas, a gente chama de parâmetros, né? Do modelo, parâmetros do perceptron, e no caso de uma rede neural, quando você olha para todos os parâmetros de todos os neurônios artificiais envolvidos, você tem os parâmetros da rede\n",
            " Então, quando você vê uma notícia do tipo assim, ah, o chat GPT ou o Lama, um modelo de linguagem grande, né? Um grande modelo de linguagem, LLM, como a gente vem chamando, tem 5 bilhões de parâmetros, o que as pessoas estão falando é que existem 5 bilhões de números como esse, tá? Números que estão representados em cada neurôniozinho desse aqui, beleza? E é muito fácil ver que esses números podem crescer de uma forma muito rápida, tá? Porque matematicamente essas contas aqui vão ser representadas por matrizes, tá bom? Então, não vou entrar no detalhe de como que a gente chega nas matrizes, mas vou te dizer aqui que, por exemplo, neste primeiro caso, olhando para isso aqui, a gente tem 4 elementos aqui na entrada, e 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 aqui nessa primeira camada escondida, né? Como a gente chama\n",
            " Então, só isso aqui dá para gente uma matriz que é 4 por 10, talvez seja 10 por 4, enfim, vai ter 40 números aqui nessa matriz\n",
            " E aí você vai fazer uma conta parecida para esse aqui, uma outra para esse aqui\n",
            " Então você vê assim, se você aumentar muito esse número de neurônios em cada camada, e em alguns modelos vai ter muito mesmo, você pode ter, sei lá, mil e tantos neurônios numa camada, mil e tantos na outra\n",
            " Mil vezes mil já dá 1 milhão, tá? Então, só pensando assim você já consegue perceber que a quantidade de parianometrôs pode crescer bastante em um modelo grande desse como o Chart GPT, ele está na ordem de bilhões\n",
            " Sim, esse tempo todo você teve medo de ser substituído por multiplicações de matrizes\n",
            " Agora, o fato que torna uma região neural tão poderosa é que ela é um modelo computacional capaz de aproximar qualquer função\n",
            " Então não é mágica, gente, é matemática\n",
            " Digo, matemática\n",
            " Eu já expliquei algumas vezes aqui no canal o que é uma função, mas vamos lá, de maneira resumida, ela seria uma entidade, um objeto que transforma uma coisa em outra coisa, sem deixar dúvidas\n",
            " Então, por exemplo, a função suco poderia transformar uma fruta no suco daquela fruta\n",
            " Laranja em suco de laranja, melancia em suco de melancia, morango em suco de morango\n",
            " Sem deixar dúvidas, se ora ela transforma laranja em suco de morango ou laranja em suco de maçã, certo? Então, isso é uma função, uma forma de transformar ou de associar elementos de um conjunto a elementos de outro conjunto, tá? Então o poder das redes norais está intimamente relacionado à nossa capacidade, a capacidade humana de representar as coisas ao nosso redor como funções\n",
            " Você pode pensar, por exemplo, que existe uma função em que você dá uma imagem e ela te diz se tem um gato ou não, certo? Ela transforma o que ela recebeu, imagem, em uma resposta\n",
            " Sim ou não? Para a pergunta, tem gato, certo? Então você poderia imaginar que existe uma função como essa\n",
            " Você poderia imaginar que tem uma função que recebe também uma imagem e conta quantos celulares existem naquela imagem, certo? Recebe uma imagem, um elemento de um conjunto\n",
            " A função faz o que ela tem que fazer, você não precisa saber exatamente como é que o processo dela funciona, mas o ponto é que ela vai associar para aquela imagem, vai te dizer quantos celulares ali existem\n",
            " Se você der a imagem de novo, quantas vezes for necessárias, certo? Ela sempre vai te dizer, olha, existem aqui 16 celulares, ela transforma isso naquilo sem deixar dúvida\n",
            " No primeiro momento isso pode parecer muito louco, mas se você parar para pensar, tudo que está no computador tem que ser representado de uma maneira matemática, na forma de números ali, porque são coisas digitais\n",
            " O computador é uma máquina de computação, então ele faz operações muito simples, apesar de serem muito poderosas, de possibilitar, por exemplo, que a gente esteja aqui conversando nesse momento, que eu possa passar a minha mensagem para você, você possa aprender, você possa comentar, aí a gente possa continuar essa discussão aqui embaixo\n",
            " Então, apesar das atividades que a gente possa fazer com o computador, dessas atividades possíveis serem bem complexas, o tipo de operação que computadores fazem nessas operações são muito simples\n",
            " Então, você pode pensar que tudo que você consegue ver no computador, seja texto, imagem, vídeo ou qualquer outra coisa, já tem uma representação matemática, uma representação numérica\n",
            " Então, com esse contexto, dá para imaginar que existe uma longa literatura, uma longa caminhada de estudos das pessoas pensando qual seria a melhor maneira de fazer esse tipo de representação de objetos da realidade num computador, qual seria a melhor maneira de fazer operações com eles\n",
            " Então, mesmo antes de você olhar para essa parte de IA e tal, você já podia fazer diversas operações com imagens, usando Photoshop, transformar uma coisa em preto e branco, fazer composições, montagens e outras coisas\n",
            " Então, todas essas operações já foram muito bem estudadas e o poder mesmo da rede neural vem dessa capacidade de receber essas coisas como dados, como sinais para aqueles perceptron, fazer operações em cima daquilo e ajustar esses parâmetros, ajustar os números de cada um daqueles neurônios ali na rede, de modo a produzir um resultado que você deseja\n",
            " Então, a gente ganha um grande poder ao ter um modelo que é bastante flexível, que é capaz de aprender praticamente qualquer função e da gente ter a capacidade de especificar para esse modelo dados como entrada, como sinais, dados na forma de números e também especificar para eles saídas, respostas espegadas também na forma de números\n",
            " Então, dando os dados, dando as saídas e tendo um processo de ajuste, um ao ritmo ali que vem dessas técnicas de aprendizado de máquina para ajustar os pesos da rede, tendo isso a gente consegue treinar\n",
            " O treinamento de uma rede neural é esse processo de ajustar esses números das contas que acontecem aí no meio\n",
            " Então, com isso a gente consegue treinar, ajusta-se a rede, de modo que ela aprenda a utilizar essas entradas, o que quer que seja que você está dando para ela, e reproduzir respostas espegadas\n",
            " É claro que há muitos outros detalhes por trás, principalmente considerando a variedade de problemas em que a gente vem aplicando redes neurais\n",
            " Por exemplo, a forma de treinar uma rede neural para reconhecer gatos em uma imagem é diferente da forma de treinar uma rede neural para ensinar um agente como um robô a caminhar dentro de um ambiente\n",
            " Mas as ideias por trás, a ideia de modelar o seu problema na forma de funções, de entender que você vai ter que passar dados, sinais ali na entrada, de que você vai ter que especificar de alguma maneira, algo que permita medir o quão correto, o quão bom a quem o teu resultado está ficando ou não, para que você possa ajustar os pesos da rede, fazer esse treinamento, essa ideia se repete em diversos tipos de problemas\n",
            " Então pode parecer muito simples, mas é realmente essa estrutura e apenas essas operações de som e multiplicação com uma função que vão se conectando a só isso realmente que a gente tem feito para construir todas essas aplicações fantásticas que têm deixado as pessoas vislumbradas\n",
            " Se você quiser entender esses detalhes de como uma rede neural é treinada, de como que esses algoritmos funcionam na prática, eu sugiro que você assista a um vídeo aqui no canal em que eu ensinei sobre PyTorch e redes neurais do zero\n",
            " Eu ensinei realmente como que você monta toda a infraestrutura para fazer o treinamento de uma rede neural utilizando a biblioteca PyTorch, que é uma biblioteca muito utilizada para resolver esse tipo de problema, e fui explicando como é que você modela o problema, como é que você entende a rede neural como uma função, como que você aproxima uma função com ela, e a gente vai evoluindo até trabalhar com imagens mesmo, discutir essas representações digitais\n",
            " Se você gostou do vídeo, não esqueça de deixar o seu like e nem de se inscrever aqui no canal para dar aquele apoio ao nosso trabalho\n",
            " Muito obrigado e até a próxima! Legendas pela comunidade Amara\n",
            "org\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('i6l3R7j95x8-medium.txt', \"w\") as result_text_file:\n",
        "  text = result3[\"text\"].split('.')\n",
        "  for sentence in text:\n",
        "    result_text_file.write(sentence)\n",
        "    result_text_file.write('\\n')"
      ],
      "metadata": {
        "id": "4PdrjOw2P3Xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CoOlOIeY6C0N"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}